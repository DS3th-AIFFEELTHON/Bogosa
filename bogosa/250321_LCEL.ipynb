{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6GUHybGwnsPh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import jsonlines\n",
        "from langchain.schema import Document\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_upstage import UpstageEmbeddings\n",
        "from langchain_milvus.vectorstores import Milvus\n",
        "from uuid import uuid4\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "import pandas as pd\n",
        "import pytz\n",
        "\n",
        "from datetime import timedelta\n",
        "from operator import itemgetter\n",
        "from langchain_teddynote.retrievers import KiwiBM25Retriever\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains.query_constructor.base import AttributeInfo\n",
        "from langchain.chains.query_constructor.base import (\n",
        "  StructuredQueryOutputParser,\n",
        "  get_query_constructor_prompt\n",
        ")\n",
        "from langchain_teddynote.evaluator import GroundednessChecker\n",
        "from langchain.retrievers.self_query.milvus import MilvusTranslator\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableLambda\n",
        "import warnings\n",
        "from langchain_core.runnables import chain\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LP2hMGEp0B2P"
      },
      "outputs": [],
      "source": [
        "embeddings = UpstageEmbeddings(\n",
        "    model='solar-embedding-1-large-query',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SPIguiAtnsPp"
      },
      "outputs": [],
      "source": [
        "def save_docs_to_jsonl(documents, file_path):\n",
        "    with jsonlines.open(file_path, mode=\"w\") as writer:\n",
        "        for doc in documents:\n",
        "            writer.write(doc.dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9cCVM_fUcsV4"
      },
      "outputs": [],
      "source": [
        "def adjust_time_filter_to_week(time_filter):\n",
        "    \"\"\"\n",
        "    특정 날짜(YYYY-MM-DD)가 주어진 경우, 해당 날짜를 포함하는 주(월~일)의\n",
        "    첫 번째 날(월요일)과 마지막 날(일요일)로 변환하는 함수.\n",
        "\n",
        "    :param time_filter: dict, {\"start_date\": datetime, \"end_date\": datetime}\n",
        "    :return: dict, {\"start_date\": datetime, \"end_date\": datetime}\n",
        "    \"\"\"\n",
        "    # Extract start_date and end_date from time_filter\n",
        "    start_date = time_filter.start_date\n",
        "    end_date = time_filter.end_date\n",
        "\n",
        "    # Handle the case where start_date or end_date is None\n",
        "    if start_date is None or end_date is None:\n",
        "        if start_date is not None and end_date is None:\n",
        "            start_of_week = start_date - timedelta(days=start_date.weekday())  # 월요일 찾기\n",
        "            end_of_week = start_of_week + timedelta(days=6)  # 해당 주 일요일 찾기\n",
        "\n",
        "            return {\n",
        "                \"start_date\": start_of_week.replace(hour=0, minute=0, second=0),\n",
        "                \"end_date\": end_of_week.replace(hour=23, minute=59, second=59)\n",
        "            }\n",
        "        elif end_date is not None and start_date is None:\n",
        "            start_of_week = end_date - timedelta(days=end_date.weekday())  # 월요일 찾기\n",
        "            end_of_week = start_of_week + timedelta(days=6)  # 해당 주 일요일 찾기\n",
        "\n",
        "            return {\n",
        "                \"start_date\": start_of_week.replace(hour=0, minute=0, second=0),\n",
        "                \"end_date\": end_of_week.replace(hour=23, minute=59, second=59)\n",
        "            }\n",
        "        else:\n",
        "            return None  # or return the time_filter as is if you prefer\n",
        "\n",
        "    # 날짜가 동일한 경우, 주의 첫 번째 날(월요일)과 마지막 날(일요일)로 변경\n",
        "    if start_date.year == end_date.year and start_date.month==end_date.month and start_date.day==end_date.day:\n",
        "        start_of_week = start_date - timedelta(days=start_date.weekday())  # 월요일 찾기\n",
        "        end_of_week = start_of_week + timedelta(days=6)  # 해당 주 일요일 찾기\n",
        "\n",
        "        return {\n",
        "            \"start_date\": start_of_week.replace(hour=0, minute=0, second=0),\n",
        "            \"end_date\": end_of_week.replace(hour=23, minute=59, second=59)\n",
        "        }\n",
        "\n",
        "    # 날짜가 다르면 기존 time_filter 유지\n",
        "    return {\n",
        "        \"start_date\": start_date,\n",
        "        \"end_date\": end_date\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oX62Lo_GcsV6"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from typing import Optional\n",
        "from pydantic import BaseModel\n",
        "import instructor\n",
        "from openai import OpenAI\n",
        "from pydantic import BaseModel, Field, field_validator\n",
        "from typing import Literal\n",
        "\n",
        "\n",
        "class TimeFilter(BaseModel):\n",
        "    start_date: Optional[datetime] = None\n",
        "    end_date: Optional[datetime] = None\n",
        "\n",
        "class SearchQuery(BaseModel):\n",
        "    query: str\n",
        "    time_filter: TimeFilter\n",
        "\n",
        "class Label(BaseModel):\n",
        "    chunk_id: int = Field(description=\"The unique identifier of the text chunk\")\n",
        "    chain_of_thought: str = Field(\n",
        "        description=\"The reasoning process used to evaluate the relevance\"\n",
        "    )\n",
        "    relevancy: int = Field(\n",
        "        description=\"Relevancy score from 0 to 10, where 10 is most relevant\",\n",
        "        ge=0,\n",
        "        le=10,\n",
        "    )\n",
        "\n",
        "class RerankedResults(BaseModel):\n",
        "    labels: list[Label] = Field(description=\"List of labeled and ranked chunks\")\n",
        "\n",
        "    @field_validator(\"labels\")\n",
        "    @classmethod\n",
        "    def model_validate(cls, v: list[Label]) -> list[Label]:\n",
        "        return sorted(v, key=lambda x: x.relevancy, reverse=True)\n",
        "\n",
        "def rerank_results(query: str, chunks: list[dict]) -> RerankedResults:\n",
        "    client = instructor.from_openai(OpenAI())\n",
        "    return client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        response_model=RerankedResults,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"\n",
        "                You are an expert search result ranker. Your task is to evaluate the relevance of each text chunk to the given query and assign a relevancy score.\n",
        "\n",
        "                For each chunk:\n",
        "                1. Analyze its content in relation to the query.\n",
        "                2. Provide a chain of thought explaining your reasoning.\n",
        "                3. Assign a relevancy score from 0 to 10, where 10 is most relevant.\n",
        "\n",
        "                Be objective and consistent in your evaluations.\n",
        "                \"\"\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"\"\"\n",
        "                <query>{{ query }}</query>\n",
        "\n",
        "                <chunks_to_rank>\n",
        "                {% for chunk in chunks %}\n",
        "                <chunk id=\"{{ chunk.id }}\">\n",
        "                    {{ chunk.text }}\n",
        "                </chunk>\n",
        "                {% endfor %}\n",
        "                </chunks_to_rank>\n",
        "\n",
        "                Please provide a RerankedResults object with a Label for each chunk.\n",
        "                \"\"\",\n",
        "            },\n",
        "        ],\n",
        "        context={\"query\": query, \"chunks\": chunks},\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7kaaAvpXcsV7"
      },
      "outputs": [],
      "source": [
        "def get_query_date(question):\n",
        "    today = datetime(2025, 1, 25)\n",
        "    days_since_last_friday = (today.weekday() - 4) % 7\n",
        "    last_friday = today - timedelta(days=days_since_last_friday)\n",
        "    issue_date = last_friday.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    client = instructor.from_openai(OpenAI())\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"o1\",\n",
        "        response_model=SearchQuery,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"\"\"\n",
        "                You are an AI assistant that extracts date ranges from financial queries.\n",
        "                The current report date is {issue_date}.\n",
        "                Your task is to extract the relevant date or date range from the user's query\n",
        "                and format it in YYYY-MM-DD format.\n",
        "                If no date is specified, answer with None value.\n",
        "                \"\"\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": question,\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    parsed_dates = adjust_time_filter_to_week(response.time_filter)\n",
        "\n",
        "    # parsed_dates를 순회하며 None인 경우도 처리\n",
        "    if parsed_dates:\n",
        "        start = parsed_dates['start_date']\n",
        "        end=parsed_dates['end_date']\n",
        "    else:\n",
        "        start=None\n",
        "        end = None\n",
        "\n",
        "    if start is None or end is None:\n",
        "        expr = None\n",
        "    else:\n",
        "        expr = f\"issue_date >= '{start.strftime('%Y%m%d')}' AND issue_date <= '{end.strftime('%Y%m%d')}'\"\n",
        "        expr = expr\n",
        "    return expr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "8U2KmujUcsV8"
      },
      "outputs": [],
      "source": [
        "def convert_to_list(example):\n",
        "    if isinstance(example[\"contexts\"], list):\n",
        "        contexts = example[\"contexts\"]\n",
        "    else:\n",
        "        try:\n",
        "            contexts = json.loads(example[\"contexts\"])\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"JSON Decode Error: {example['contexts']} - {e}\")\n",
        "            contexts = []\n",
        "    return {\"contexts\": contexts}\n",
        "\n",
        "def generate_expr(question: str) -> dict:\n",
        "    expr = get_query_date(question)\n",
        "    return {\"expr\": expr}\n",
        "\n",
        "def reranking(docs, question, k=15):\n",
        "    chunks = [{\"id\": idx, \"issue_date\": doc.metadata['issue_date'],  \"text\": doc.page_content} for idx, doc in enumerate(docs)]\n",
        "    documents_with_metadata = [{\"text\": doc.page_content, \"metadata\": doc.metadata} for doc in docs]\n",
        "    reranked_results = rerank_results(query=question, chunks=chunks)\n",
        "\n",
        "    chunk_dict = {chunk[\"id\"]: chunk[\"text\"] for chunk in chunks}\n",
        "    top_k_results = [chunk_dict.get(label.chunk_id, \"\") for label in reranked_results.labels[:k] if label.chunk_id in chunk_dict]\n",
        "\n",
        "    reranked_results_with_metadata = []\n",
        "    for reranked_result in top_k_results:\n",
        "        page_content = reranked_result\n",
        "\n",
        "        matching_metadata = None\n",
        "        for doc in documents_with_metadata:\n",
        "            if doc[\"text\"] == page_content:\n",
        "                matching_metadata = doc[\"metadata\"]\n",
        "                break\n",
        "\n",
        "        document = Document(\n",
        "            metadata=matching_metadata,\n",
        "            page_content=page_content\n",
        "        )\n",
        "        reranked_results_with_metadata.append(document)\n",
        "\n",
        "    context_rerankedNbm25 = reranked_results_with_metadata\n",
        "    return context_rerankedNbm25\n",
        "\n",
        "text_prompt = PromptTemplate.from_template(\n",
        "'''\n",
        "Today is '2025-01-25'. \n",
        "You are an assistant for question-answering tasks.\n",
        "Use the following pieces of retrieved context to answer the question.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Answer in Korean. Answer in detail.\n",
        "\n",
        "#Question:\n",
        "{question}\n",
        "#Context:\n",
        "{context}\n",
        "\n",
        "#Answer:'''\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "question_answer_relevant = GroundednessChecker(\n",
        "  llm=ChatOpenAI(model='o1', temperature=0), target='question-answer'\n",
        ").create()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GroundnessQuestionScore(score='yes')"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = '2주 전 은행채 발행액은?'\n",
        "\n",
        "question_answer_relevant.invoke({'question': question, 'answer': text_chain.invoke({'question': question})})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GroundnessQuestionScore(score='yes')"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = '2주 전 은행채 발행액은?'\n",
        "\n",
        "question_answer_relevant.invoke({'question': question, 'answer': text_chain.invoke({'question': question})})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GroundnessQuestionScore(score='yes')"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = '2주 전 은행채 발행액은?'\n",
        "\n",
        "question_answer_relevant.invoke({'question': question, 'answer': text_chain.invoke({'question': question})})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_upstage import UpstageGroundednessCheck\n",
        "\n",
        "# 업스테이지 Groundness Checker 생성\n",
        "upstage_groundedness_check = UpstageGroundednessCheck()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2주 전(즉, 2025년 1월 10일 기준) 공시에 따르면 은행채 발행액은 2조 6,100억 원이었다고 명시되어 있습니다. 해당 자료에서 “전 주 대비 9,700억 원 증가”라는 언급이 있으나, 2주 전 시점인 1월 10일 공시상의 구체적인 발행액 수치는 2조 6,100억 원으로 나타납니다. 따라서 2025년 1월 25일을 기준으로 2주 전 은행채 발행액은 2조 6,100억 원입니다.'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_chain.invoke({'question': question})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = reranking(question=question, docs=vectorstore_text.as_retriever(search_kwargs={'k': 25, 'expr':get_query_date('2주 전 은행채 발행액은?')}).invoke(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'page': 13, 'source': './raw_pdf_copy3\\\\KISWeekly제1118호(20250110).pdf', 'summary': '- 은행채 발행액: 2조 6,100억 원, 전 주 대비 9,700억 원 증가\\n- 한국수출입은행 연내물 할인채: 언더 10.3bp\\n- 우리은행 연내물 할인채: 언더 15.9bp\\n- 국민은행 1년 만기 이표채: 언더 7.9bp\\n- 농협은행 1년 만기 이표채: 언더 6.6bp\\n- 기타금융채 발행액: 3조 4,600억 원, 전 주 대비 2조 8,700억 원 증가\\n- A- 등급 키움캐피탈 및 엠캐피탈: 언더 20bp 이상 발행 강세\\n- 엠캐피탈: 새마을금고중앙회 지주 편입으로 OUTLOOK 상향\\n- A+ 등급 롯데캐피탈 및 메리츠캐피탈 강세 지속\\n- AA- 등급 캐피탈채 발행 강세 지속', 'issue_date': '20250110', 'pk': 'de99baa8-ee4c-4479-b78d-ae5768509c5d', 'type': 'text'}, page_content='은행채 발행액은 2조 6,100 억 원으로 전 주 대비 9,700억원 증가했다. 은행채 발행량이 증가세를 이어간 가운데, 연내물 할인채 위주의 강세를 지속했다. 국책은행 중에서 한국수출입은행의 연내물 할인채가 언더 10.3bp로 발행되었고, 시중은행 중에서 우리은행의 연내물 할인채가 언더 15.9bp로 발행되며 강세를 이어 갔다. 이어서 이표채 중에서 역시 연내물 위주의 강세가 지속되었다. 국민은행의 1년만기 이표채가 언더 7.9bp, 농협은행의 1년만기 이표채가 언더 6.6bp로 발행되며 강세를 보였다. 이어서 한국산업은행의 1년구 간 이표채 역시 발행 강세를 보이며 마감했다. 기타금융채 발행액은 3조 4,600억원으로 전 주 대비 2조 8,700억원 증가했다.'),\n",
              " Document(metadata={'page': 12, 'source': './raw_pdf_copy3\\\\KISWeekly제1118호(20250110).pdf', 'summary': '- 금융채 시장 발행 증가세 전환\\n- 은행채 발행량 증가, 연내물 스프레드 축소\\n  - 1년 구간: 언더 8.0bp\\n  - 3년 구간: 4.0bp 축소\\n  - 5년 구간: 1.0bp 축소\\n  - 10년 구간: 1.5bp 축소\\n- 기타금융채 발행량 증가 전환\\n  - 1년 구간: 언더 7.5bp\\n  - 3년 구간: 3.0bp 축소\\n  - 5년 구간: 언더 1.0bp 축소\\n  - 10년 구간: 2.0bp 축소\\n- 자료 출처: KIS자산평가', 'issue_date': '20250110', 'pk': '087d8ea3-87e0-4f38-b933-ad5212119c77', 'type': 'text'}, page_content='은행채 발행시장은 발행량을 증가고, 연내물 위주로 큰폭의 스프레드를 축소했다. 은행채 1년 구간이 언 더 8.0bp로 지속적인 축소세를 나타냈으며, 그밖에도 3년 및 10년 구간으로도 축소세를 지속했다. 3년 구간 이 4.0bp 촉소했고, 5년 및 10년 구간이 각각 1.0bp, 1.5bp 축소세를 보이며 마감했다. 기타금융채 발행시장은 발행량을 증가 전환했다. 기타금융채 역시 연내물을 중심의 스프레드 축소세를 이어갔다. 1년 구간이 언더 7.5bp로 스프레드를 더욱 축소했고, 이어서 3년 구간은 3.0bp 축소되었다.'),\n",
              " Document(metadata={'page': 16, 'source': './raw_pdf_copy3\\\\KISWeekly제1118호(20250110).pdf', 'summary': '- 은행채 유통시장은 연내물 위주의 강세로 시작.\\n- 주 초반, 연내물 중심으로 3.0bp 이상의 강세.\\n- 주중 강세 확대, AA0 등급까지 3.0bp 이상 지속.\\n- 주 후반, 1년 물 중심으로 강세 지속하며 마감.\\n- 기타금융채시장도 유통 강세로 시작.\\n- 주 초반, 연내물 위주로 2.5bp 이상의 강세.\\n- 중장기물 중심으로 강세폭 확대.\\n- 주 후반, AA+ 등급 카드채 중심으로 강세 지속하며 마감.', 'issue_date': '20250110', 'pk': '45882dfc-1e3e-45d9-9a9e-9cc1dc7b3943', 'type': 'text'}, page_content='은행채는 유통시장은 연내물 위주의 강세로 출발했다. 주 초반 연내물을 중심으로 언어 3.0bp 이상의 큰 강세로 시작한 은행채 시장은 주중으로 갈수록 강세가 확대되는 모습을 나타냈다. 특시 산금 및 중금, 은행 채 AA0까지의 전반적인 등급에서 언더 3.0bp 이상의 강세를 지속했다. 주 후반 역시 강세 폭을 줄이기는 했 지만 연내물 1년 물을 중심으로 강세를 지속하며 마감했다. 기타금융채시장 역시 유통 강세로 출발했다. 주 초반 연내물 위주로 언더 2.5bp 이상의 강세를 보이던 기 타금융채 시장은 주중 비슷한 폭으로 강세를 지속했다.'),\n",
              " Document(metadata={'page': 10, 'source': './raw_pdf_copy3\\\\KISWeekly제1118호(20250110).pdf', 'summary': '- 지표, 특수채AAA 수익률 곡선의 금리변동폭: 단위 % 및 bp\\n- 자료 출처: KIS자산평가\\n- 지표 수익률 범위: 통안 3M~2Y, 국고 2.5Y~30Y\\n- BEI(Breakeven Inflation Rate) 변동: 단위 % 및 bp\\n- 국공채 발행현황: 국고 24-12 2,000억원, 국고 24-9 1,000억원 통합발행', 'issue_date': '20250110', 'pk': '63707603-097c-4a56-a543-5ec220466eaf', 'type': 'text'}, page_content='지난주 발행시장은 국고 24-12 2,000억원, 국고 24-9 1,000억원이 통합발행 되었다.'),\n",
              " Document(metadata={'page': 26, 'source': './raw_pdf_copy3\\\\KISWeekly제1118호(20250110).pdf', 'summary': '- 금주 CD 발행: 2건, 8,000억 원\\n- 하나은행(AAA): 1년물 3.18% 발행\\n- 부산은행(AAA): 364일물 2.99% 발행\\n- CD 금리: 전 주 강세 흐름 지속\\n- CP 발행액: 127,619억 원, 전주 대비 44,262억 원 증가\\n- 단기사채 발행액: 228,478억 원, 전주 대비 88,572억 원 증가\\n- A1 등급 발행액: CP 90,909억 원, ESTB 185,561억 원\\n- A1 등급 CP: 전주 대비 49,284억 원 증가\\n- A1 등급 ESTB: 전주 대비 53,310억 원 증가', 'issue_date': '20250110', 'pk': 'f569e131-5e8c-4c3f-bc84-509778b6ae8f', 'type': 'text'}, page_content='금주 CD 발행은 국내 은행 2건 8,000억 원을 기록했다. 금주 하나은행(AAA)은 1년물을 3.18%, 부산은행 (AAA)이 364일물을 2.99%로 발행했다. CD금리는 전 주의 강세 흐름을 이어나가면서 큰 폭으로 강세 발행 되면서 마무리 되었다.'),\n",
              " Document(metadata={'page': 18, 'source': './raw_pdf_copy3\\\\KISWeekly제1118호(20250110).pdf', 'summary': '- 이번 주 회사채 발행금액: 1,000억 원\\n- 만기금액: 1,600억 원\\n- 우리금융지주: 2년 만기 회사채 발행, 민평대비 -4bp 낙찰금리\\n- 차주 한화에어로스페이스(AA-): 2,000억 원 규모 회사채 수요예측\\n- 차주 LG헬로비전(AA-): 1,000억 원 규모 회사채 수요예측', 'issue_date': '20250110', 'pk': 'a41e45a4-8e93-4872-bf44-4340f3180b5c', 'type': 'text'}, page_content='이번 주 회사채 발행금액은 1,000억 원, 만기금액은 1,600억 원을 나타냈다.'),\n",
              " Document(metadata={'page': 26, 'source': './raw_pdf_copy3\\\\KISWeekly제1118호(20250110).pdf', 'summary': '- 금주 CD 발행: 2건, 8,000억 원\\n- 하나은행(AAA): 1년물 3.18% 발행\\n- 부산은행(AAA): 364일물 2.99% 발행\\n- CD 금리: 전 주 강세 흐름 지속\\n- CP 발행액: 127,619억 원, 전주 대비 44,262억 원 증가\\n- 단기사채 발행액: 228,478억 원, 전주 대비 88,572억 원 증가\\n- A1 등급 발행액: CP 90,909억 원, ESTB 185,561억 원\\n- A1 등급 CP: 전주 대비 49,284억 원 증가\\n- A1 등급 ESTB: 전주 대비 53,310억 원 증가', 'issue_date': '20250110', 'pk': '10559d57-964a-4584-809c-52eb8455aa98', 'type': 'text'}, page_content='금주 CP 발행액은 127,619억원으로 전주 대비 44,262억원 증가하였다. 단기사채의 발행액은 228,478억원 으로 전주 대비 88,572억원 증가하였다. A1 등급 발행액은 CP 90,909억원, ESTB 185,561억원으로 전주 대 비 각 49,284억원 증가, 53,310억원 증가했다.'),\n",
              " Document(metadata={'page': 25, 'source': './raw_pdf_copy3\\\\KISWeekly제1118호(20250110).pdf', 'summary': '- CD금리(AAA등급 3개월물 기준): 15bp 하락하여 3.00%로 마감\\n- CD-은행채 스프레드: 3.0bp 축소하여 -11.5bp로 마감\\n- CD 발행: 국내 은행 2건, 8,000억 원\\n- CP금리(91일, A1등급 기준): 5.0bp 하락하여 3.31%로 마감\\n- CP-회사채 스프레드: -1.8bp 축소\\n- CP-CD 스프레드: 31.0bp 확대\\n- 신규 발행 건수: 전 주 대비 큰 폭으로 감소\\n- 1년물 정기예금: 3.0% 초과 수준에서 신규 발행\\n- 기간: 2024-01-11~현재, 자료 출처: KIS자산평가, 금융투자협회', 'issue_date': '20250110', 'pk': 'f41cf220-f65f-4bdc-a8d8-6cd12b61a185', 'type': 'text'}, page_content='CD금리(AAA등급 3개월물 기준)는 지표물 강세 발행으로 전주 대비 15bp 하락한 3.00%로 마감하였다. CD- 은행채(AAA등급 3개월물 기준) 스프레드는 전주 대비 3.-bp 축소한 -11.5bp로 마감했다.금주 CD 발행은 국 내 은행 2건 8,000억 원을 기록했다. 반면 CP금리(91일, A1등급 기준)는 전주 대비 5.0bp 하락한 3.31%로 마감하였다. CP-회사채(AA등급 3개 월물 기준) 스프레드는 전주 대비 축소된 -1.8bp를 기록했고, CP-CD 스프레드는 전 주 대비 확대된 31.0bp 로 마감했다. 금주 단기 시장에는 CD금리의 강세 흐름이 이어지면서 큰 폭으로 하락하는 흐름이 나타났다.'),\n",
              " Document(metadata={'page': 18, 'source': './raw_pdf_copy3\\\\KISWeekly제1118호(20250110).pdf', 'summary': '- 이번 주 회사채 발행금액: 1,000억 원\\n- 만기금액: 1,600억 원\\n- 우리금융지주: 2년 만기 회사채 발행, 민평대비 -4bp 낙찰금리\\n- 차주 한화에어로스페이스(AA-): 2,000억 원 규모 회사채 수요예측\\n- 차주 LG헬로비전(AA-): 1,000억 원 규모 회사채 수요예측', 'issue_date': '20250110', 'pk': 'd626c049-3e3e-42e3-a496-397ae188f3c7', 'type': 'text'}, page_content='우리금융지주는 2년만기 회사채 발행을 성공적으로 해내며 민평대비 -4bp 에 낙찰금리를 설정했다. 차주는 한화에어로스페이스(AA-)가 채 무상환을 위한 2,000억원 규모의 회사채 수요예측에 나서며, LG헬로비전(AA-)도 채무상환을 위해 1,000억 원 규모의 회사채 수요예측을 진행한다.'),\n",
              " Document(metadata={'page': 19, 'source': './raw_pdf_copy3\\\\KISWeekly제1118호(20250110).pdf', 'summary': '- 회사채 유통시장이 전주 대비 활발한 거래를 보임\\n- 전체 유통량: 6조 949억 원 (전주 대비 4조 1587.2억 원 증가)\\n- 등급별 유통량:\\n  - AAA 등급: 31.03% (6.16%P 증가)\\n  - AA 등급: 57.37% (5.35%P 감소)\\n  - A 등급: 9.50% (0.33%P 증가)\\n- 잔존 만기 별 유통량:\\n  - 1년 미만: 40.25% (4.57%P 감소)\\n  - 1년~3년: 46.67% (15.43%P 증가)\\n  - 3년~5년: 4.40% (0.88%P 증가)\\n  - 5년 이상: 8.66% (11.74%P 감소)', 'issue_date': '20250110', 'pk': 'a859ff3e-8601-46ee-9259-ce0858574527', 'type': 'text'}, page_content='금주 회사채 유통시장은 전주에 비해 활발한 거래가 이루어졌다. 전체 유통량은 6조 949억 원으로 전 주 대 비 4조 1587.2억 원 증가했다. 등급별 유통량은 AAA 등급은 전주 대비 6.16%P 증가한 31.03%를 차지했고, AA 등급은 전주 대비 5.35%P 감소한 57.37%를 차지했다.'),\n",
              " Document(metadata={'page': 25, 'source': './raw_pdf_copy3\\\\KISWeekly제1118호(20250110).pdf', 'summary': '- CD금리(AAA등급 3개월물 기준): 15bp 하락하여 3.00%로 마감\\n- CD-은행채 스프레드: 3.0bp 축소하여 -11.5bp로 마감\\n- CD 발행: 국내 은행 2건, 8,000억 원\\n- CP금리(91일, A1등급 기준): 5.0bp 하락하여 3.31%로 마감\\n- CP-회사채 스프레드: -1.8bp 축소\\n- CP-CD 스프레드: 31.0bp 확대\\n- 신규 발행 건수: 전 주 대비 큰 폭으로 감소\\n- 1년물 정기예금: 3.0% 초과 수준에서 신규 발행\\n- 기간: 2024-01-11~현재, 자료 출처: KIS자산평가, 금융투자협회', 'issue_date': '20250110', 'pk': '148bdb97-5616-4b8e-914b-abbe58e56cd6', 'type': 'text'}, page_content='신규 발행 건수는 전 주 대비 큰 폭으로 감소하였으나, 90일 구간 근처에서 이전의 수준 을 비교적 큰 폭으로 하회하는 수준에서 발행하면서 기준금리 인하에 대한 기대감이 일부 반영되는 모습을 엿볼 수 있었다. 이는 유동화 종목들에도 반영되는 흐름이 나타났다.정기예금 종목들의 경우 1년물 기준 3.0%를 웃도는 수준에서 신규발행되면서 강세 흐름이 온전히 반영되는 경향을 보였다.'),\n",
              " Document(metadata={'page': 28, 'source': './raw_pdf_copy3\\\\KISWeekly제1118호(20250110).pdf', 'summary': '- 금주 정기예금 발행금액: 30,536 억 원 (전주 대비 27,136 억 원 증가)\\n- 호가: 365일물 기준 3.00%\\n- 부동산 관련 대출 발행금액: 5,550 억 원 (전주 대비 206 억 원 감소)\\n  - 수도권: 4,069 억 원\\n  - 그 외 지역: 1,481 억 원\\n- PF물 90일 기준 발행금리: 3.65% (전주 대비 약강세)', 'issue_date': '20250110', 'pk': 'b21e5116-10e1-46ac-a98b-d643b40bcffe', 'type': 'text'}, page_content='금주 부동산 관련 대출 발행금액은 5,550 억원으로 전주 대비 206억원 감소했다. 그 중 수도권이 4,069억 원, 그 외 지역이 1,481 억 원을 차지했다. PF물 90일 기준 발행금리는 3.65%로 전주 대비 약강세로 마무리 되었다.'),\n",
              " Document(metadata={'page': 27, 'source': './raw_pdf_copy3\\\\KISWeekly제1118호(20250110).pdf', 'summary': '- 2024-01-01부터의 유동화 발행금액: 105,433억원\\n- 전주 대비 증가: 35,706억원\\n- 기초자산: 부동산 관련 대출이 가장 많이 발행\\n- 정기예금이 그 뒤를 이음\\n- 자료 출처: KIS자산평가', 'issue_date': '20250110', 'pk': 'e3dad674-792e-4665-9078-259fee33a137', 'type': 'text'}, page_content='금주 유동화 발행금액은 105,433억원으로 전주 대비 35,706억원 증가하였다. 기초자산은 부동산 관련 대 출이 가장 많이 발행되었고, 정기예금이 그 뒤를 이었다.'),\n",
              " Document(metadata={'page': 13, 'source': './raw_pdf_copy3\\\\KISWeekly제1118호(20250110).pdf', 'summary': '- 은행채 발행액: 2조 6,100억 원, 전 주 대비 9,700억 원 증가\\n- 한국수출입은행 연내물 할인채: 언더 10.3bp\\n- 우리은행 연내물 할인채: 언더 15.9bp\\n- 국민은행 1년 만기 이표채: 언더 7.9bp\\n- 농협은행 1년 만기 이표채: 언더 6.6bp\\n- 기타금융채 발행액: 3조 4,600억 원, 전 주 대비 2조 8,700억 원 증가\\n- A- 등급 키움캐피탈 및 엠캐피탈: 언더 20bp 이상 발행 강세\\n- 엠캐피탈: 새마을금고중앙회 지주 편입으로 OUTLOOK 상향\\n- A+ 등급 롯데캐피탈 및 메리츠캐피탈 강세 지속\\n- AA- 등급 캐피탈채 발행 강세 지속', 'issue_date': '20250110', 'pk': '685f44ba-8b7a-4f0a-b7e3-02c8142e904d', 'type': 'text'}, page_content='기타금융채 발행량은 큰 폭으로 확대하는 모습을 보였다.'),\n",
              " Document(metadata={'page': 28, 'source': './raw_pdf_copy3\\\\KISWeekly제1118호(20250110).pdf', 'summary': '- 금주 정기예금 발행금액: 30,536 억 원 (전주 대비 27,136 억 원 증가)\\n- 호가: 365일물 기준 3.00%\\n- 부동산 관련 대출 발행금액: 5,550 억 원 (전주 대비 206 억 원 감소)\\n  - 수도권: 4,069 억 원\\n  - 그 외 지역: 1,481 억 원\\n- PF물 90일 기준 발행금리: 3.65% (전주 대비 약강세)', 'issue_date': '20250110', 'pk': '3c89882e-daf9-4d0c-9403-71481530683f', 'type': 'text'}, page_content='금주 정기예금 발행금액은 30,536 억 원으로 전주 대비 27,136억원 증가했다. 호가는 365일물 기준 3.00% 수준이었다.')]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Issue Date: 20250110\\nContent: 은행채 발행액은 2조 6,100 억 원으로 전 주 대비 9,700억원 증가했다. 은행채 발행량이 증가세를 이어간 가운데, 연내물 할인채 위주의 강세를 지속했다. 국책은행 중에서 한국수출입은행의 연내물 할인채가 언더 10.3bp로 발행되었고, 시중은행 중에서 우리은행의 연내물 할인채가 언더 15.9bp로 발행되며 강세를 이어 갔다. 이어서 이표채 중에서 역시 연내물 위주의 강세가 지속되었다. 국민은행의 1년만기 이표채가 언더 7.9bp, 농협은행의 1년만기 이표채가 언더 6.6bp로 발행되며 강세를 보였다. 이어서 한국산업은행의 1년구 간 이표채 역시 발행 강세를 보이며 마감했다. 기타금융채 발행액은 3조 4,600억원으로 전 주 대비 2조 8,700억원 증가했다.\\n\\nIssue Date: 20250110\\nContent: 은행채 발행시장은 발행량을 증가고, 연내물 위주로 큰폭의 스프레드를 축소했다. 은행채 1년 구간이 언 더 8.0bp로 지속적인 축소세를 나타냈으며, 그밖에도 3년 및 10년 구간으로도 축소세를 지속했다. 3년 구간 이 4.0bp 촉소했고, 5년 및 10년 구간이 각각 1.0bp, 1.5bp 축소세를 보이며 마감했다. 기타금융채 발행시장은 발행량을 증가 전환했다. 기타금융채 역시 연내물을 중심의 스프레드 축소세를 이어갔다. 1년 구간이 언더 7.5bp로 스프레드를 더욱 축소했고, 이어서 3년 구간은 3.0bp 축소되었다.\\n\\nIssue Date: 20250110\\nContent: 은행채는 유통시장은 연내물 위주의 강세로 출발했다. 주 초반 연내물을 중심으로 언어 3.0bp 이상의 큰 강세로 시작한 은행채 시장은 주중으로 갈수록 강세가 확대되는 모습을 나타냈다. 특시 산금 및 중금, 은행 채 AA0까지의 전반적인 등급에서 언더 3.0bp 이상의 강세를 지속했다. 주 후반 역시 강세 폭을 줄이기는 했 지만 연내물 1년 물을 중심으로 강세를 지속하며 마감했다. 기타금융채시장 역시 유통 강세로 출발했다. 주 초반 연내물 위주로 언더 2.5bp 이상의 강세를 보이던 기 타금융채 시장은 주중 비슷한 폭으로 강세를 지속했다.\\n\\nIssue Date: 20250110\\nContent: 지난주 발행시장은 국고 24-12 2,000억원, 국고 24-9 1,000억원이 통합발행 되었다.\\n\\nIssue Date: 20250110\\nContent: 이번 주 회사채 발행금액은 1,000억 원, 만기금액은 1,600억 원을 나타냈다.\\n\\nIssue Date: 20250110\\nContent: 금주 CP 발행액은 127,619억원으로 전주 대비 44,262억원 증가하였다. 단기사채의 발행액은 228,478억원 으로 전주 대비 88,572억원 증가하였다. A1 등급 발행액은 CP 90,909억원, ESTB 185,561억원으로 전주 대 비 각 49,284억원 증가, 53,310억원 증가했다.\\n\\nIssue Date: 20250110\\nContent: 금주 CD 발행은 국내 은행 2건 8,000억 원을 기록했다. 금주 하나은행(AAA)은 1년물을 3.18%, 부산은행 (AAA)이 364일물을 2.99%로 발행했다. CD금리는 전 주의 강세 흐름을 이어나가면서 큰 폭으로 강세 발행 되면서 마무리 되었다.\\n\\nIssue Date: 20250110\\nContent: CD금리(AAA등급 3개월물 기준)는 지표물 강세 발행으로 전주 대비 15bp 하락한 3.00%로 마감하였다. CD- 은행채(AAA등급 3개월물 기준) 스프레드는 전주 대비 3.-bp 축소한 -11.5bp로 마감했다.금주 CD 발행은 국 내 은행 2건 8,000억 원을 기록했다. 반면 CP금리(91일, A1등급 기준)는 전주 대비 5.0bp 하락한 3.31%로 마감하였다. CP-회사채(AA등급 3개 월물 기준) 스프레드는 전주 대비 축소된 -1.8bp를 기록했고, CP-CD 스프레드는 전 주 대비 확대된 31.0bp 로 마감했다. 금주 단기 시장에는 CD금리의 강세 흐름이 이어지면서 큰 폭으로 하락하는 흐름이 나타났다.\\n\\nIssue Date: 20250110\\nContent: 우리금융지주는 2년만기 회사채 발행을 성공적으로 해내며 민평대비 -4bp 에 낙찰금리를 설정했다. 차주는 한화에어로스페이스(AA-)가 채 무상환을 위한 2,000억원 규모의 회사채 수요예측에 나서며, LG헬로비전(AA-)도 채무상환을 위해 1,000억 원 규모의 회사채 수요예측을 진행한다.\\n\\nIssue Date: 20250110\\nContent: 기타금융채 발행량은 큰 폭으로 확대하는 모습을 보였다.\\n\\nIssue Date: 20250110\\nContent: 당사 기준 회사채 3년 만기 AAA 등급의 국고 대비 크레딧 스프레드는 전주보다 3.2bp 감소한 50.6bp를 나 타냈고, AA0등급은 전주보다 0.5bp 하락한 63.1bp, A0 등급은 전주와 동일한 124.2bp를 기록하였다. 국고 채 금리 하락에 연동해 회사채 금리도 하락했다.\\n\\nIssue Date: 20250110\\nContent: 금주 회사채 유통시장은 전주에 비해 활발한 거래가 이루어졌다. 전체 유통량은 6조 949억 원으로 전 주 대 비 4조 1587.2억 원 증가했다. 등급별 유통량은 AAA 등급은 전주 대비 6.16%P 증가한 31.03%를 차지했고, AA 등급은 전주 대비 5.35%P 감소한 57.37%를 차지했다.\\n\\nIssue Date: 20250110\\nContent: 신규 발행 건수는 전 주 대비 큰 폭으로 감소하였으나, 90일 구간 근처에서 이전의 수준 을 비교적 큰 폭으로 하회하는 수준에서 발행하면서 기준금리 인하에 대한 기대감이 일부 반영되는 모습을 엿볼 수 있었다. 이는 유동화 종목들에도 반영되는 흐름이 나타났다.정기예금 종목들의 경우 1년물 기준 3.0%를 웃도는 수준에서 신규발행되면서 강세 흐름이 온전히 반영되는 경향을 보였다.\\n\\nIssue Date: 20250110\\nContent: 금주 부동산 관련 대출 발행금액은 5,550 억원으로 전주 대비 206억원 감소했다. 그 중 수도권이 4,069억 원, 그 외 지역이 1,481 억 원을 차지했다. PF물 90일 기준 발행금리는 3.65%로 전주 대비 약강세로 마무리 되었다.\\n\\nIssue Date: 20250110\\nContent: 금주 유동화 발행금액은 105,433억원으로 전주 대비 35,706억원 증가하였다. 기초자산은 부동산 관련 대 출이 가장 많이 발행되었고, 정기예금이 그 뒤를 이었다.'"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "format_docs(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nRg0xKV7csV9"
      },
      "outputs": [],
      "source": [
        "question_answer_relevant = GroundednessChecker(\n",
        "  llm=ChatOpenAI(model='gpt-4o-mini', temperature=0), target='question-answer'\n",
        ").create()\n",
        "\n",
        "@chain\n",
        "def kill_table(result):\n",
        "    if question_answer_relevant.invoke({'question': result['question'], 'answer': result['text']}).score == 'no':\n",
        "        result['context'] = table_chain.invoke({'question': result['question']})\n",
        "    else:\n",
        "        result['context'] = result['text']\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tmSVpgXOnsPq"
      },
      "outputs": [],
      "source": [
        "filepath = './chunked_jsonl/250313_text_semantic_per_80.jsonl'\n",
        "\n",
        "splitted_doc_text = []\n",
        "with open(filepath, 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        if line.startswith('\\n('):\n",
        "            continue\n",
        "        data = json.loads(line)\n",
        "\n",
        "        doc = Document(\n",
        "            page_content=data['page_content'],\n",
        "            metadata=data['metadata']\n",
        "        )\n",
        "        splitted_doc_text.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# splitted_doc_text = []\n",
        "# for i in splitted_doc:\n",
        "#   if i.metadata['issue_date'][-2:] != '00':\n",
        "#     splitted_doc_text.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "enxxBnxqnsPq"
      },
      "outputs": [],
      "source": [
        "URI = 'http://127.0.0.1:19530'\n",
        "\n",
        "vectorstore_text = Milvus(\n",
        "    embedding_function=embeddings,\n",
        "    connection_args={'uri':URI},\n",
        "    index_params={'index_type': 'AUTOINDEX', 'metric_type': 'IP'},\n",
        "    collection_name='text_semantic_per_80_00_test'\n",
        ")\n",
        "\n",
        "# uuids = [str(uuid4()) for _ in range(len(splitted_doc_text))]\n",
        "\n",
        "# vectorstore_text.add_documents(\n",
        "#   documents=splitted_doc_text,\n",
        "#   ids=uuids\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "vectorstore_predict = Milvus(\n",
        "    embedding_function=embeddings,\n",
        "    connection_args={'uri':URI},\n",
        "    index_params={'index_type': 'AUTOINDEX', 'metric_type': 'IP'},\n",
        "    collection_name='text_semantic_per_80_00'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vt32Cqx40B2S"
      },
      "outputs": [],
      "source": [
        "\n",
        "milvus_retriever_text = vectorstore_text.as_retriever(\n",
        "    search_kwargs={'k':20}\n",
        ")\n",
        "\n",
        "bm25_retriever_text = KiwiBM25Retriever.from_documents(\n",
        "    splitted_doc_text\n",
        ")\n",
        "bm25_retriever_text.k = 20\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8ZcPzPGo0B2T"
      },
      "outputs": [],
      "source": [
        "filepath = './chunked_jsonl/table_v7.jsonl'\n",
        "\n",
        "splitted_doc_table = []\n",
        "with open(filepath, 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        if line.startswith('\\n('):\n",
        "            continue\n",
        "        data = json.loads(line)\n",
        "\n",
        "        doc = Document(\n",
        "            page_content=data['page_content'],\n",
        "            metadata=data['metadata']\n",
        "        )\n",
        "        splitted_doc_table.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mIBqnNnj0B2U"
      },
      "outputs": [],
      "source": [
        "embeddings=UpstageEmbeddings(\n",
        "    model='solar-embedding-1-large-query'\n",
        ")\n",
        "\n",
        "vectorstore_table = Milvus(\n",
        "  embedding_function=embeddings,\n",
        "  connection_args={'uri':URI},\n",
        "  index_params={'index_type': 'AUTOINDEX', 'metric_type': 'IP'},\n",
        "  collection_name='table_v7'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "q8Ay3G9E0B2W"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
        "\n",
        "bm25_retriever_table = KiwiBM25Retriever.from_documents(\n",
        "    splitted_doc_table\n",
        ")\n",
        "bm25_retriever_table.k = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_docs(docs):\n",
        "    # 각 문서의 issue_date와 page_content를 함께 출력하도록 포맷합니다.\n",
        "    return \"\\n\\n\".join(\n",
        "        f\"Issue Date: {doc.metadata.get('issue_date', 'Unknown')}\\nContent: {doc.page_content}\"\n",
        "        for doc in docs\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "CFn0Jq1zcsWB"
      },
      "outputs": [],
      "source": [
        "llm_text = ChatOpenAI(model='o1', temperature=1)\n",
        "\n",
        "answer = []\n",
        "\n",
        "text_chain = (\n",
        "    RunnableParallel(\n",
        "        question=itemgetter('question')\n",
        "    ).assign(expr = lambda x: get_query_date(x['question'])\n",
        "    ).assign(context_raw=lambda x: RunnableLambda(\n",
        "            lambda _: vectorstore_text.as_retriever(\n",
        "                search_kwargs={'expr': x['expr'], 'k': 25}\n",
        "            ).invoke(x['question'])\n",
        "        ).invoke({}),\n",
        "    ).assign(\n",
        "        context=lambda x: reranking(\n",
        "            list({doc.metadata.get(\"pk\"): doc for doc in (x['context_raw'])}.values()),\n",
        "            x['question'], 15\n",
        "        )\n",
        "    ).assign(\n",
        "        formatted_context=lambda x: format_docs(x['context'])\n",
        "    )\n",
        "    | RunnableLambda(\n",
        "        lambda x: {\n",
        "            \"question\": x['question'],\n",
        "            \"context\": x['formatted_context'],  \n",
        "        }\n",
        "    )\n",
        "    | text_prompt\n",
        "    | llm_text\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm_text = ChatOpenAI(model='o1', temperature=1)\n",
        "\n",
        "answer = []\n",
        "\n",
        "predict_prompt = PromptTemplate.from_template(\n",
        "  '''You are future-predicting expert AI chatbot about financial.\n",
        "  주어진 정보는 retrieved context들이야. 이 정보를 바탕으로 미래를 예측해줘.\n",
        "\n",
        "  If one of the table or text says it doesn't know or it can't answer, don't mention with that.\n",
        "  주어진 예측을 한 근거도 함께 자세히 설명해줘. 왜 그런 예측을 어떤 걸 근거로 내놓았는지 알려줘.\n",
        "  Don't answer with the specific numbers.\n",
        "\n",
        "  #Question:\n",
        "  {question}\n",
        "\n",
        "  #Context:\n",
        "  {context}\n",
        "  '''\n",
        ")\n",
        "\n",
        "predict_expression = 'issue_date >= \"20241224\" AND issue_date <=\"20250124\"'\n",
        "predict_chain = (\n",
        "    RunnableParallel(\n",
        "        question=itemgetter('question')\n",
        "    ).assign(context=lambda x: RunnableLambda(\n",
        "            lambda _: vectorstore_text.as_retriever(\n",
        "                search_kwargs={'k': 20, 'expr':predict_expression}\n",
        "            ).invoke(x['question'])\n",
        "        ).invoke({}),\n",
        "    ).assign(\n",
        "        formatted_context=lambda x: format_docs(x['context'])\n",
        "    )\n",
        "    | RunnableLambda(\n",
        "        lambda x: {\n",
        "            \"question\": x['question'],\n",
        "            \"context\": x['formatted_context'],  \n",
        "        }\n",
        "    )\n",
        "    | predict_prompt\n",
        "    | llm_text\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_chain_2 = (\n",
        "    RunnableParallel(\n",
        "        question=itemgetter('question')\n",
        "    ).assign(expr = lambda x: get_query_date(x['question'])\n",
        "    ).assign(milvus=lambda x: RunnableLambda(\n",
        "            lambda _: vectorstore_text.as_retriever(\n",
        "                search_kwargs={'k': 25}\n",
        "            ).invoke(x['question'])\n",
        "        ).invoke({}),\n",
        "        bm25=lambda x: bm25_retriever_text.invoke(x['question'])\n",
        "    ).assign(\n",
        "        context=lambda x: reranking(\n",
        "            list({doc.metadata.get(\"pk\"): doc for doc in (x['milvus'] + x['bm25'])}.values()),\n",
        "            x['question'], 20\n",
        "        )\n",
        "    ).assign(\n",
        "        formatted_context=lambda x: format_docs(x['context'])\n",
        "    )\n",
        "    | RunnableLambda(\n",
        "        lambda x: {\n",
        "            \"question\": x['question'],\n",
        "            \"context\": x['formatted_context'],  \n",
        "        }\n",
        "    )\n",
        "    | text_prompt\n",
        "    | llm_text\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4oqqtQXd0B2a"
      },
      "outputs": [],
      "source": [
        "table_prompt = PromptTemplate.from_template(\n",
        "'''You are an assistant for question-answering tasks.\n",
        "Use the following pieces of retrieved table to answer the question.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Answer in Korean. Answer in detail.\n",
        "\n",
        "#Question:\n",
        "{question}\n",
        "#Context:\n",
        "{context}\n",
        "\n",
        "#Answer:'''\n",
        ")\n",
        "\n",
        "table_chain = (\n",
        "    RunnableParallel(\n",
        "        question=itemgetter('question')\n",
        "    ).assign(expr = lambda x: get_query_date(x['question'])\n",
        "    ).assign(milvus=lambda x: RunnableLambda(\n",
        "            lambda _: vectorstore_table.as_retriever(\n",
        "                search_kwargs={'expr': x['expr'], 'k': 10}\n",
        "            ).invoke(x['question'])\n",
        "        ).invoke({}),\n",
        "        bm25_raw=lambda x: bm25_retriever_table.invoke(x['question'])\n",
        "    ).assign(\n",
        "        bm25_filtered=lambda x: [\n",
        "            doc for doc in x[\"bm25_raw\"]\n",
        "            if not x[\"expr\"] or (\n",
        "                x[\"expr\"].split(\"'\")[1] <= doc.metadata.get(\"issue_date\", \"\") <= x[\"expr\"].split(\"'\")[3]\n",
        "            )\n",
        "        ],\n",
        "    ).assign(\n",
        "    context=lambda x: list({\n",
        "        doc.metadata.get(\"pk\"): doc \n",
        "        for doc in (x['milvus'] + x['bm25_filtered'])\n",
        "    }.values())\n",
        "    ).assign(\n",
        "        formatted_context=lambda x: format_docs(x['context'])\n",
        "    )\n",
        "    | RunnableLambda(\n",
        "        lambda x: {\n",
        "            \"question\": x['question'],\n",
        "            \"context\": x['formatted_context'],  #\n",
        "        }\n",
        "    )\n",
        "    | text_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wu4CNzco0B2b"
      },
      "outputs": [],
      "source": [
        "llm_general = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
        "\n",
        "general_prompt = PromptTemplate.from_template(\n",
        "  '''You are question-answering AI chatbot about financial reports.\n",
        "  주어진 정보는 retrieved context들이야. 이 정보를 바탕으로 질문에 대해 자세히 설명해줘.\n",
        "\n",
        "  If one of the table or text says it doesn't know or it can't answer, don't mention with that.\n",
        "  And some questions may not be answered simply with context, but rather require inference. In those cases, answer by inference.\n",
        "\n",
        "  #Question:\n",
        "  {question}\n",
        "\n",
        "  #Context:\n",
        "  {context}\n",
        "  '''\n",
        ")\n",
        "\n",
        "date_chain = (\n",
        "    RunnableParallel(\n",
        "        question=itemgetter('question'),\n",
        "        text=text_chain,\n",
        "    )\n",
        "    | kill_table\n",
        "    | general_prompt\n",
        "    | llm_general\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "general_chain = (\n",
        "    RunnableParallel(\n",
        "        question=itemgetter('question'),\n",
        "        text=text_chain_2,\n",
        "    )\n",
        "    | kill_table\n",
        "    | general_prompt\n",
        "    | llm_general\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "KJ8ghEh5csWE"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Milvus\n",
        "\n",
        "embd = UpstageEmbeddings(\n",
        "    model='solar-embedding-1-large-query',\n",
        ")\n",
        "\n",
        "vectorstore_raptor = Milvus(\n",
        "    embedding_function=embd,\n",
        "    connection_args={'uri':URI},\n",
        "    index_params={'index_type': 'AUTOINDEX', 'metric_type': 'IP'},\n",
        "    collection_name='raptor_v3'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "OSzdlQ2b0B2e"
      },
      "outputs": [],
      "source": [
        "metadata_field_info = [\n",
        "  AttributeInfo(\n",
        "    name='source',\n",
        "    description='문서의 번호. 네 자리의 숫자와 \"호\"로 이루어져 있다. 현재 1090호부터 1120호까지 존재한다.',\n",
        "    type='string',\n",
        "  ),\n",
        "]\n",
        "\n",
        "prompt_query = get_query_constructor_prompt(\n",
        "  'summary of weekly financial report about bonds',\n",
        "  metadata_field_info\n",
        ")\n",
        "\n",
        "output_parser = StructuredQueryOutputParser.from_components()\n",
        "\n",
        "query_llm = ChatOpenAI(model='gpt-4-turbo-preview', temperature=0)\n",
        "query_constructor = prompt_query | query_llm | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "LNE7Gv1kcsWE"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.self_query.milvus import MilvusTranslator\n",
        "\n",
        "prompt_raptor = PromptTemplate.from_template(\n",
        "'''You are an assistant for question-answering tasks.\n",
        "Use the following pieces of retrieved context to answer the question.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Answer in Korean. Answer in detail.\n",
        "If the context mentions an unrelated date, do not mention that part.\n",
        "Summarize and organize your answers based on the various issues that apply to the period.\n",
        "\n",
        "#Question:\n",
        "{question}\n",
        "#Context:\n",
        "{context}\n",
        "\n",
        "#Answer:'''\n",
        ")\n",
        "\n",
        "retriever_raptor = SelfQueryRetriever(\n",
        "  query_constructor=query_constructor,\n",
        "  vectorstore=vectorstore_raptor,\n",
        "  structured_query_translator=MilvusTranslator(),\n",
        "  search_kwargs={'k': 10}\n",
        ")\n",
        "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
        "\n",
        "raptor_chain = (\n",
        "    RunnableParallel(\n",
        "        question=itemgetter('question')\n",
        "    ).assign(expr = lambda x: get_query_date(x['question'])\n",
        "    ).assign(context=lambda x: retriever_raptor.invoke(x['question']))\n",
        "    | RunnableLambda(\n",
        "        lambda x: {\n",
        "            \"question\": x['question'],\n",
        "            \"context\": x['context'],\n",
        "        }\n",
        "    )\n",
        "    | prompt_raptor\n",
        "    | llm\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "kevg3dtQcsWF"
      },
      "outputs": [],
      "source": [
        "raptor_date_chain = (\n",
        "    RunnableParallel(\n",
        "        question=itemgetter('question')\n",
        "    ).assign(expr = lambda x: get_query_date(x['question'])\n",
        "    ).assign(context=lambda x: RunnableLambda(\n",
        "            lambda _: vectorstore_raptor.as_retriever(\n",
        "                search_kwargs={'expr': x['expr'], 'k': 10}\n",
        "            ).invoke(x['question'])\n",
        "        ).invoke({})\n",
        "    )\n",
        "    | RunnableLambda(\n",
        "        lambda x: {\n",
        "            \"question\": x['question'],\n",
        "            \"context\": x['context'],\n",
        "        }\n",
        "    )\n",
        "    | prompt_raptor\n",
        "    | llm\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SvbguJfqcsWF"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt_routing_2 = PromptTemplate.from_template(\n",
        "  '''You are an expert at routing a user question to the appropriate data source.\n",
        "\n",
        "If the user is asking for a brief summary, route it to the '요약' datasource.\n",
        "If the user is asking for more detailed or general information, route it to the '일반' datasource.\n",
        "If the user is asking for some prediction, route it to the '예측' datasource.\n",
        "\n",
        "Just answer with one word of datasource.\n",
        "\n",
        "Today is January 25th, 2025. Only classify as predictions asking about things after today.\n",
        "\n",
        "  <question>\n",
        "  {question}\n",
        "  </question>\n",
        "\n",
        "  datasource:'''\n",
        ")\n",
        "\n",
        "chain_routing_2 = (\n",
        "  {'question': RunnablePassthrough()}\n",
        "  | prompt_routing_2\n",
        "  | ChatOpenAI(model='gpt-4o-mini')\n",
        "  | StrOutputParser()\n",
        ")\n",
        "\n",
        "prompt_routing = PromptTemplate.from_template(\n",
        "  '''주어진 사용자 질문을 `날짜`, `호수`, `일반` 중 하나로 분류하세요. 한 단어 이상으로 응답하지 마세요.\n",
        "  If user question has the expression about date, route it to the '날짜' datasource.\n",
        "\n",
        "  <question>\n",
        "  {question}\n",
        "  </question>\n",
        "\n",
        "  Classification:'''\n",
        ")\n",
        "\n",
        "chain_routing = (\n",
        "  {'question': RunnablePassthrough()}\n",
        "  | prompt_routing\n",
        "  | ChatOpenAI(model='o1')\n",
        "  | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "K5SYwc4AcsWF"
      },
      "outputs": [],
      "source": [
        "def route_2(info):\n",
        "  if '요약' in info['topic'].lower():\n",
        "    print('raptor_date_chain')\n",
        "    return raptor_date_chain\n",
        "  elif '예측' in info['topic'].lower():\n",
        "    print('predict_chain')\n",
        "    return predict_chain\n",
        "  else:\n",
        "    print('date_chain')\n",
        "    return date_chain\n",
        "\n",
        "def route(info):\n",
        "  if '날짜' in info['topic'].lower():\n",
        "    info['topic'] = chain_routing_2.invoke(info['question'])\n",
        "    return route_2(info)\n",
        "  elif '호수' in info['topic'].lower():\n",
        "    print('raptor_chain')\n",
        "    return raptor_chain\n",
        "  else:\n",
        "    print('general_chain')\n",
        "    return general_chain\n",
        "\n",
        "\n",
        "full_chain = (\n",
        "  {'topic': chain_routing, 'question': itemgetter('question')}\n",
        "  | RunnableLambda(\n",
        "    route\n",
        "  )\n",
        "  | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "J2kYvPKecsWG"
      },
      "outputs": [],
      "source": [
        "filepath = './chunked_jsonl/image_v2.jsonl'\n",
        "\n",
        "splitted_doc_image = []\n",
        "with open(filepath, 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        if line.startswith('\\n('):\n",
        "            continue\n",
        "        data = json.loads(line)\n",
        "\n",
        "        doc = Document(\n",
        "            page_content=data['page_content'],\n",
        "            metadata=data['metadata']\n",
        "        )\n",
        "        splitted_doc_image.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "VNuo52ExcsWG"
      },
      "outputs": [],
      "source": [
        "URI = 'http://127.0.0.1:19530'\n",
        "\n",
        "vectorstore_image = Milvus(\n",
        "    embedding_function=embeddings,\n",
        "    connection_args={'uri':URI},\n",
        "    index_params={'index_type': 'AUTOINDEX', 'metric_type': 'IP'},\n",
        "    collection_name='image_v4'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "xjBncZUkcsWG"
      },
      "outputs": [],
      "source": [
        "retriever_image = vectorstore_image.as_retriever(search_kwargs={'k': 3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "-nXYKCIAcsWG"
      },
      "outputs": [],
      "source": [
        "query_retrieval_relevant = GroundednessChecker(\n",
        "  llm=ChatOpenAI(model='gpt-4o-mini', temperature=0), target='question-retrieval'\n",
        ").create()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "3ZSXtfghcsWG"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "\n",
        "def ask(question):\n",
        "    expr = get_query_date(question)\n",
        "    answer = full_chain.invoke({'question': question})\n",
        "    print(answer)\n",
        "    rc('font', family='Malgun Gothic')\n",
        "    plt.rcParams['axes.unicode_minus'] = False\n",
        "    context = retriever_image.invoke(question, expr=expr)\n",
        "    for i in context:\n",
        "        rar = query_retrieval_relevant.invoke({'context': i, 'question': question})\n",
        "        if rar.score=='yes':\n",
        "            plt.title('참고 자료')\n",
        "            image_path = i.metadata['image'].replace('raw_pdf_copy3', 'parsed_pdf')\n",
        "            img = Image.open(image_path)\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "date_chain\n",
            "2주 전 은행채 발행액은 총 3,000백만원입니다. 이 금액은 2025년 1월 10일 기준으로 발행된 여러 은행채의 발행액을 합산한 결과입니다. 구체적으로는 국민은행, 산금, 우리은행, 농업금융채권, 부산은행 등 다양한 은행에서 발행된 채권들이 포함되어 있습니다. 각 은행채의 발행액은 다음과 같습니다:\n",
            "\n",
            "- 국민은행4501이표일(03)1-06: 2,000백만원\n",
            "- 산금25신이0106-0106-1: 1,400백만원\n",
            "- 우리은행29-01-할인01-갑-06: 3,000백만원\n",
            "- 농업금융채권(은행)2025-01이1Y-A: 700백만원\n",
            "- 부산은행2025-01이1A-09: 1,000백만원\n",
            "- 산금25신이0103-0109-1: 3,000백만원\n",
            "- 산금25신이0200-0109-2: 7,000백만원\n",
            "- 산금25신이0109-0110-1: 5,000백만원\n",
            "- 한국수출입금융2501라-할인-304: 3,000백만원\n",
            "\n",
            "이 중에서 2주 전 발행된 은행채의 총합이 3,000백만원이라는 점이 중요합니다.\n"
          ]
        }
      ],
      "source": [
        "ask('2주 전 은행채 발행액은?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "date_chain\n",
            "2주 전 은행채 발행액은 총 3,000백만원입니다. 이 금액은 2025년 1월 10일 기준으로 발행된 여러 은행채의 발행액을 합산한 결과입니다. 구체적으로는 국민은행, 산금, 우리은행, 농업금융채권, 부산은행 등 다양한 은행에서 발행된 채권들이 포함되어 있습니다. 각 은행채의 발행액은 다음과 같습니다:\n",
            "\n",
            "- 국민은행4501이표일(03)1-06: 2,000백만원\n",
            "- 산금25신이0106-0106-1: 1,400백만원\n",
            "- 우리은행29-01-할인01-갑-06: 3,000백만원\n",
            "- 농업금융채권(은행)2025-01이1Y-A: 700백만원\n",
            "- 부산은행2025-01이1A-09: 1,000백만원\n",
            "- 산금25신이0103-0109-1: 3,000백만원\n",
            "- 산금25신이0200-0109-2: 7,000백만원\n",
            "- 산금25신이0109-0110-1: 5,000백만원\n",
            "- 한국수출입금융2501라-할인-304: 3,000백만원\n",
            "\n",
            "이들 중에서 2주 전 발행된 은행채의 총합이 3,000백만원이라는 점이 중요합니다.\n"
          ]
        }
      ],
      "source": [
        "ask('2주 전 은행채 발행액은?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "date_chain\n",
            "2주 전 은행채 발행액은 총 15,100백만원입니다. 이 발행액은 여러 종류의 은행채로 구성되어 있으며, 구체적인 발행 내역은 다음과 같습니다:\n",
            "\n",
            "- 국민은행4501이표일(03)1-06: 2,000백만원\n",
            "- 산금25신이0106-0106-1: 1,400백만원\n",
            "- 우리은행29-01-할인01-갑-06: 3,000백만원\n",
            "- 농업금융채권(은행)2025-01이1Y-A: 700백만원\n",
            "- 부산은행2025-01이1A-09: 1,000백만원\n",
            "- 산금25신이0103-0109-1: 3,000백만원\n",
            "- 산금25신이0200-0109-2: 7,000백만원\n",
            "- 산금25신이0109-0110-1: 5,000백만원\n",
            "- 한국수출입금융2501라-할인-304: 3,000백만원\n",
            "\n",
            "이러한 발행액은 은행채 시장의 유동성과 자금 조달 상황을 반영하고 있습니다.\n"
          ]
        }
      ],
      "source": [
        "ask('2주 전 은행채 발행액은?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "date_chain\n",
            "2주 전 은행채 발행액은 총 3,000백만원입니다. 이 금액은 2025년 1월 10일에 발행된 은행채의 발행액을 기준으로 하며, 여러 은행에서 발행된 다양한 채권들이 포함되어 있습니다. 각 은행별 발행액은 다음과 같습니다:\n",
            "\n",
            "1. 국민은행4501이표일(03)1-06: 2,000백만원\n",
            "2. 산금25신이0106-0106-1: 1,400백만원\n",
            "3. 우리은행29-01-할인01-갑-06: 3,000백만원\n",
            "4. 농업금융채권(은행)2025-01이1Y-A: 700백만원\n",
            "5. 부산은행2025-01이1A-09: 1,000백만원\n",
            "6. 산금25신이0103-0109-1: 3,000백만원\n",
            "7. 산금25신이0200-0109-2: 7,000백만원\n",
            "8. 산금25신이0109-0110-1: 5,000백만원\n",
            "9. 한국수출입금융2501라-할인-304: 3,000백만원\n",
            "\n",
            "이들 채권의 발행액을 모두 합산한 결과, 2주 전의 총 발행액이 3,000백만원으로 확인됩니다.\n"
          ]
        }
      ],
      "source": [
        "ask('2주 전 은행채 발행액은?')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
